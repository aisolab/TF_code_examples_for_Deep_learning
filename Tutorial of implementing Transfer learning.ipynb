{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial of implementing Transfer learning\n",
    "- ** Ch1. Supervised pre-training for an auxilary task**  \n",
    "mnist 데이터 중 숫자 0~4를 예측하는 5개의 hidden layer를 가지는 Deep Neural Network를 학습하고, 이 모형의 weight들을 save\n",
    "  \n",
    "  \n",
    "- ** Ch2. Transfer learning 1**  \n",
    "Ch1에서 학습한 모형의 전체 weight를 restore한다. 이후 hidden layer를 제외한 output layer의 weight를 다시 initialize를 하고,\n",
    "5~9에 해당하는 mnist image를 넣어서, output layer의 weight만 training 한다. 또한 Ch3에서 hidden layer의 weight를 활용하기위해서 hidden layer의 weight들만 저장하고, 후에 Ch3에서 restore한다.  \n",
    "\n",
    "    *(이 예제에서는 hidden layer의 weight는 학습을 통해 update하지 않는다. 전체 Network를 update를 해야하는 가의 여부에 대한 guide는 아래의 링크를 참고)*  \n",
    "  \n",
    "    링크 : http://cs231n.github.io/transfer-learning/\n",
    "  \n",
    "  \n",
    "- ** Ch3. Transfer learning 2**  \n",
    "Ch2에서 저장한 모형의 hidden layer의 weight를 restore한다. Ch2의 예제와 다른 점은 5~9의 5개의 숫자를 분류하기위해 output layer의 weight만 training 했다면, 이번 예제에서는 0~9의 숫자를 예측하기위해 output layer의 architecture를 바꾸고, weight를 initialize한 뒤, architecture가 바뀐 output layer의 weight만 update 한다.  \n",
    "  \n",
    "  \n",
    "***전체 내용을 구성하기위한 reference는 아래와 같다.***  \n",
    "* 참고 \n",
    "\n",
    "    링크1 : https://wookayin.github.io/TensorFlowKR-2017-talk-bestpractice/ko/#1  \n",
    "    링크2 : https://github.com/ageron/handson-ml/blob/master/11_deep_learning.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules and mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import shutil \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.examples.tutorials.mnist import input_data # load mnist dataset\n",
    "mnist = input_data.read_data_sets(train_dir = './MNIST_data', one_hot = True, reshape = True, seed = 777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DNNClassifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnnClassifier:\n",
    "    def __init__(self, sess, n_features, n_class, hidden_dims = [100, 100, 100, 100, 100],\n",
    "               activation_fn = tf.nn.elu, initializer = tf.contrib.layers.variance_scaling_initializer()):\n",
    "        self._sess = sess\n",
    "        \n",
    "        with tf.variable_scope('input_layer'):\n",
    "            self._x = tf.placeholder(dtype = tf.float32, shape = [None, n_features])\n",
    "            self._y = tf.placeholder(dtype = tf.float32, shape = [None, n_class])\n",
    "                \n",
    "        _net = self._x\n",
    "            \n",
    "        for layer, h_dim in enumerate(hidden_dims):\n",
    "            with tf.variable_scope('hidden_layer{}'.format(layer + 1)):\n",
    "                _net = tf.layers.dense(inputs = _net, units = h_dim, activation = activation_fn,\n",
    "                                        kernel_initializer = initializer)\n",
    "                    \n",
    "        with tf.variable_scope('output_layer'):\n",
    "            self._score = tf.layers.dense(inputs = _net, units = n_class,\n",
    "                                             kernel_initializer = tf.contrib.layers.xavier_initializer())\n",
    "                \n",
    "        with tf.variable_scope('loss'):\n",
    "            self._ce_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = self._y, logits = self._score))\n",
    "                \n",
    "        with tf.variable_scope('predict'):\n",
    "            self._prediction = tf.argmax(input = self._score, axis = -1)\n",
    "                \n",
    "    def predict(self, x_data):\n",
    "        feed_predict = {self._x : x_data}\n",
    "        return self._sess.run(fetches = self._prediction, feed_dict = feed_predict)                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Solver class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver:\n",
    "    def __init__(self, sess, model, optimizer = tf.train.AdamOptimizer, var_list = None):\n",
    "        self._sess = sess\n",
    "        self._model = model # DnnClassifier의 class의 instance를 input으로 받는다\n",
    "        self._lr = tf.placeholder(dtype = tf.float32)\n",
    "        self._optimizer = optimizer(self._lr)\n",
    "        self._training_op = self._optimizer.minimize(loss = self._model._ce_loss, var_list = var_list)\n",
    "            \n",
    "    def train(self, x_data, y_data, lr):\n",
    "        feed_train = {self._model._x : x_data,\n",
    "                      self._model._y : y_data,\n",
    "                      self._lr : lr}\n",
    "        return self._sess.run(fetches = [self._training_op, self._model._ce_loss], feed_dict = feed_train)\n",
    "    \n",
    "    def evaluate(self, x_data, y_data):\n",
    "        feed_loss = {self._model._x : x_data, self._model._y : y_data}\n",
    "        return self._sess.run(fetches = self._model._ce_loss, feed_dict = feed_loss)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch1. Supervised pre-training for an auxilary task\n",
    "0~4를 예측하는 5개의 hidden layer를 가지는 Deep Neural Network를 학습한다. 추후 이 모형의 hideen layer들의 weight는 5~9를 예측하는 Deep Neural Network의 hidden layer의 weight 값으로 활용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mnist image 중 0~4에 해당되는 image와 label만 따로 뽑는다.\n",
    "'''\n",
    "x_train1 = mnist.train.images[np.argmax(mnist.train.labels, axis=1) < 5]\n",
    "y_train1 = mnist.train.labels[np.argmax(mnist.train.labels, axis=1) < 5][:,:5]\n",
    "x_valid1 = mnist.validation.images[np.argmax(mnist.validation.labels, axis=1) < 5]\n",
    "y_valid1 = mnist.validation.labels[np.argmax(mnist.validation.labels, axis=1) < 5][:,:5]\n",
    "x_test1 = mnist.test.images[np.argmax(mnist.test.labels, axis=1) < 5]\n",
    "y_test1 = mnist.test.labels[np.argmax(mnist.test.labels, axis=1) < 5][:,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate DNN model and Adam solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "pre_trained_model = DnnClassifier(sess = sess, n_class = 5, n_features = 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_opt1 = Solver(sess = sess, model = pre_trained_model, optimizer = tf.train.AdamOptimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pre_trained' in os.listdir():\n",
    "    shutil.rmtree('pre_trained')\n",
    "os.mkdir('pre_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :   0, tr_loss : 1.510, val_loss : 1.059\n",
      "step : 100, tr_loss : 0.026, val_loss : 0.131\n",
      "step : 200, tr_loss : 0.067, val_loss : 0.038\n",
      "epoch :   0, tr_loss : 0.106, val_loss : 0.098\n",
      "step :   0, tr_loss : 0.133, val_loss : 0.067\n",
      "step : 100, tr_loss : 0.049, val_loss : 0.168\n",
      "step : 200, tr_loss : 0.008, val_loss : 0.012\n",
      "epoch :   1, tr_loss : 0.047, val_loss : 0.046\n",
      "step :   0, tr_loss : 0.044, val_loss : 0.010\n",
      "step : 100, tr_loss : 0.043, val_loss : 0.040\n",
      "step : 200, tr_loss : 0.059, val_loss : 0.022\n",
      "epoch :   2, tr_loss : 0.029, val_loss : 0.034\n",
      "step :   0, tr_loss : 0.013, val_loss : 0.034\n",
      "step : 100, tr_loss : 0.006, val_loss : 0.005\n",
      "step : 200, tr_loss : 0.035, val_loss : 0.036\n",
      "epoch :   3, tr_loss : 0.021, val_loss : 0.034\n",
      "step :   0, tr_loss : 0.006, val_loss : 0.067\n",
      "step : 100, tr_loss : 0.032, val_loss : 0.056\n",
      "step : 200, tr_loss : 0.005, val_loss : 0.076\n",
      "epoch :   4, tr_loss : 0.021, val_loss : 0.040\n",
      "step :   0, tr_loss : 0.021, val_loss : 0.015\n",
      "step : 100, tr_loss : 0.001, val_loss : 0.052\n",
      "step : 200, tr_loss : 0.080, val_loss : 0.026\n",
      "epoch :   5, tr_loss : 0.013, val_loss : 0.032\n",
      "step :   0, tr_loss : 0.004, val_loss : 0.005\n",
      "step : 100, tr_loss : 0.024, val_loss : 0.002\n",
      "step : 200, tr_loss : 0.015, val_loss : 0.039\n",
      "epoch :   6, tr_loss : 0.015, val_loss : 0.035\n",
      "step :   0, tr_loss : 0.000, val_loss : 0.013\n",
      "step : 100, tr_loss : 0.013, val_loss : 0.026\n",
      "step : 200, tr_loss : 0.015, val_loss : 0.058\n",
      "epoch :   7, tr_loss : 0.019, val_loss : 0.044\n",
      "step :   0, tr_loss : 0.003, val_loss : 0.035\n",
      "step : 100, tr_loss : 0.001, val_loss : 0.098\n",
      "step : 200, tr_loss : 0.001, val_loss : 0.010\n",
      "epoch :   8, tr_loss : 0.008, val_loss : 0.029\n",
      "step :   0, tr_loss : 0.007, val_loss : 0.001\n",
      "step : 100, tr_loss : 0.000, val_loss : 0.091\n",
      "step : 200, tr_loss : 0.100, val_loss : 0.002\n",
      "epoch :   9, tr_loss : 0.009, val_loss : 0.031\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "max_checks_without_progress = 5\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    avg_tr_loss, avg_val_loss = 0, 0\n",
    "    total_batch = int(x_train1.shape[0] / batch_size)\n",
    "    \n",
    "    for step in range(total_batch):\n",
    "        tr_indices = np.random.randint(low = 0, high = x_train1.shape[0], size = batch_size)\n",
    "        val_indices = np.random.randint(low = 0, high = x_valid1.shape[0], size = batch_size)\n",
    "        batch_xs, batch_ys = x_train1[tr_indices], y_train1[tr_indices]\n",
    "        val_xs, val_ys = x_valid1[val_indices], y_valid1[val_indices]\n",
    "        _, tr_loss = adam_opt1.train(x_data = batch_xs, y_data = batch_ys, lr = 1e-3)\n",
    "        val_loss = adam_opt1.evaluate(x_data = val_xs, y_data = val_ys)\n",
    "        \n",
    "        avg_tr_loss += tr_loss / total_batch \n",
    "        avg_val_loss += val_loss / total_batch\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print('step : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(step, tr_loss, val_loss))\n",
    "\n",
    "    print('epoch : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(epoch, avg_tr_loss, avg_val_loss))\n",
    "    # early stopping : epoch 단위로\n",
    "    if avg_val_loss < best_loss: # epoch 당 avg_val_loss가 낮은 시점의 모형을 저장한다.\n",
    "        save_path = saver.save(sess = sess, save_path = './pre_trained/pre_trained_model.ckpt')\n",
    "        best_loss = avg_val_loss\n",
    "        checks_without_progress = 0\n",
    "    else:\n",
    "        checks_without_progress += 1\n",
    "        if checks_without_progress > max_checks_without_progress:\n",
    "            print('Early stopping')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 99.18%\n"
     ]
    }
   ],
   "source": [
    "hat = pre_trained_model.predict(x_data = x_test1)\n",
    "print('test accuracy : {:.2%}'.format(np.mean(hat == np.argmax(y_test1, axis = 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch2. Transfer learning 1\n",
    "Ch1에서 학습한 모형을 restore하고, output layer의 weight만 initialize를 한다. 그리고 숫자 5~9에 해당하는 mnist image를 feed하여 output layer의 weight만 update한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mnist image 중 5~9에 해당되는 image와 label만 따로 뽑는다.\n",
    "'''\n",
    "x_train2 = mnist.train.images[np.argmax(mnist.train.labels, axis = 1) >= 5]\n",
    "y_train2 = mnist.train.labels[np.argmax(mnist.train.labels, axis = 1) >= 5][:,5:]\n",
    "x_valid2 = mnist.validation.images[np.argmax(mnist.validation.labels, axis=1) >= 5]\n",
    "y_valid2 = mnist.validation.labels[np.argmax(mnist.validation.labels, axis=1) >= 5][:,5:]\n",
    "x_test2 = mnist.test.images[np.argmax(mnist.test.labels, axis=1) >= 5]\n",
    "y_test2 = mnist.test.labels[np.argmax(mnist.test.labels, axis=1) >= 5][:,5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "del pre_trained_model, adam_opt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "transfer_model1 = DnnClassifier(sess = sess, n_class = 5, n_features = 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore all weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./pre_trained/pre_trained_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "0~4에 대하여 학습한 모형을 restore하면 위의 main_model과 variable_scope가 같으므로,\n",
    "transfer_model1의 weight들에는 pre_trained_model의 weight들의 값이 저장된다.\n",
    "'''\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess = sess, save_path = './pre_trained/pre_trained_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "output layer의 weight만 update 하는 것이 목적이므로, 정상적으로 잘 작동하는 지 확인을 하기위해서\n",
    "Transfer learning을 하기전에 hidden layer들의 weight들을 따로 저장해놓는다.\n",
    "'''\n",
    "before_hidden_weights = sess.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope ='hidden'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 99.01%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "restore가 잘 되었는 지 확인한다.\n",
    "pre_trained_model의 학습이 epoch 8 일 때의, weight를 restore한 결과물이다.\n",
    "'''\n",
    "hat = transfer_model1.predict(x_data = x_test1)\n",
    "print('test accuracy : {:.2%}'.format(np.mean(hat == np.argmax(y_test1, axis = 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37235136803126928"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "0~4를 분류하는 모형의 weight를 이용하여 5~9를 예측하므로 test accuracy가 상당히 낮은 것이 당연하다.\n",
    "'''\n",
    "hat = transfer_model1.predict(x_data = x_test2)\n",
    "np.mean(hat == np.argmax(y_test2, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Adam solver and initialize weights of output layer and initial parameters of Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'output_layer/dense/kernel:0' shape=(100, 5) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/bias:0' shape=(5,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "hidden layer의 weight는 update하지 않으므로 (frozen), output_layer만 update 하기 위해서, update 해야 할\n",
    "variable만 아래처럼 뽑아낼 수 있다. 아래의 list를 Solver의 var_list에 전달한다.\n",
    "'''\n",
    "tf.contrib.framework.get_trainable_variables(scope = 'output_layer')\n",
    "# tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'output_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning\n",
    "adam_opt2 = Solver(sess = sess, model = transfer_model1,\n",
    "                    optimizer = tf.train.AdamOptimizer,\n",
    "                    var_list = tf.contrib.framework.get_trainable_variables(scope = 'output_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden_layer1/dense/kernel:0' shape=(784, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer1/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer2/dense/kernel:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer2/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer3/dense/kernel:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer3/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer4/dense/kernel:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer4/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer5/dense/kernel:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer5/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/kernel:0' shape=(100, 5) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/bias:0' shape=(5,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/kernel/Adam:0' shape=(100, 5) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/kernel/Adam_1:0' shape=(100, 5) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/bias/Adam:0' shape=(5,) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/bias/Adam_1:0' shape=(5,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "먼저 output_layer의 weight와 Transfer learning을 하는 데에 Adam optimizer를 사용하므로 Adam optimizer의 parameter의 initial value를\n",
    "initialize해야한다.\n",
    "'''\n",
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/kernel/Adam:0' shape=(100, 5) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/kernel/Adam_1:0' shape=(100, 5) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/bias/Adam:0' shape=(5,) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/bias/Adam_1:0' shape=(5,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'output_layer/dense/kernel:0' shape=(100, 5) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/bias:0' shape=(5,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.contrib.framework.get_trainable_variables(scope = 'output_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'output_layer/dense/kernel:0' shape=(100, 5) dtype=float32_ref>, <tf.Variable 'output_layer/dense/bias:0' shape=(5,) dtype=float32_ref>, <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>, <tf.Variable 'output_layer/dense/kernel/Adam:0' shape=(100, 5) dtype=float32_ref>, <tf.Variable 'output_layer/dense/kernel/Adam_1:0' shape=(100, 5) dtype=float32_ref>, <tf.Variable 'output_layer/dense/bias/Adam:0' shape=(5,) dtype=float32_ref>, <tf.Variable 'output_layer/dense/bias/Adam_1:0' shape=(5,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "vars_params = tf.contrib.framework.get_trainable_variables(scope = 'output_layer') + tf.global_variables()[-6:]\n",
    "print(vars_params)\n",
    "sess.run(tf.variables_initializer(var_list = vars_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :   0, tr_loss : 3.998, val_loss : 4.143\n",
      "step : 100, tr_loss : 1.194, val_loss : 0.740\n",
      "step : 200, tr_loss : 0.697, val_loss : 0.503\n",
      "epoch :   0, tr_loss : 1.131, val_loss : 1.066\n",
      "step :   0, tr_loss : 0.798, val_loss : 0.498\n",
      "step : 100, tr_loss : 0.566, val_loss : 0.425\n",
      "step : 200, tr_loss : 0.420, val_loss : 0.396\n",
      "epoch :   1, tr_loss : 0.462, val_loss : 0.452\n",
      "step :   0, tr_loss : 0.488, val_loss : 0.337\n",
      "step : 100, tr_loss : 0.531, val_loss : 0.524\n",
      "step : 200, tr_loss : 0.427, val_loss : 0.343\n",
      "epoch :   2, tr_loss : 0.385, val_loss : 0.358\n",
      "step :   0, tr_loss : 0.255, val_loss : 0.512\n",
      "step : 100, tr_loss : 0.429, val_loss : 0.315\n",
      "step : 200, tr_loss : 0.257, val_loss : 0.431\n",
      "epoch :   3, tr_loss : 0.338, val_loss : 0.314\n",
      "step :   0, tr_loss : 0.238, val_loss : 0.262\n",
      "step : 100, tr_loss : 0.315, val_loss : 0.391\n",
      "step : 200, tr_loss : 0.332, val_loss : 0.272\n",
      "epoch :   4, tr_loss : 0.306, val_loss : 0.294\n",
      "step :   0, tr_loss : 0.262, val_loss : 0.225\n",
      "step : 100, tr_loss : 0.300, val_loss : 0.316\n",
      "step : 200, tr_loss : 0.167, val_loss : 0.284\n",
      "epoch :   5, tr_loss : 0.288, val_loss : 0.283\n",
      "step :   0, tr_loss : 0.263, val_loss : 0.312\n",
      "step : 100, tr_loss : 0.175, val_loss : 0.332\n",
      "step : 200, tr_loss : 0.206, val_loss : 0.198\n",
      "epoch :   6, tr_loss : 0.276, val_loss : 0.258\n",
      "step :   0, tr_loss : 0.208, val_loss : 0.287\n",
      "step : 100, tr_loss : 0.255, val_loss : 0.225\n",
      "step : 200, tr_loss : 0.214, val_loss : 0.378\n",
      "epoch :   7, tr_loss : 0.263, val_loss : 0.263\n",
      "step :   0, tr_loss : 0.381, val_loss : 0.178\n",
      "step : 100, tr_loss : 0.206, val_loss : 0.208\n",
      "step : 200, tr_loss : 0.254, val_loss : 0.163\n",
      "epoch :   8, tr_loss : 0.251, val_loss : 0.246\n",
      "step :   0, tr_loss : 0.304, val_loss : 0.286\n",
      "step : 100, tr_loss : 0.314, val_loss : 0.230\n",
      "step : 200, tr_loss : 0.217, val_loss : 0.168\n",
      "epoch :   9, tr_loss : 0.251, val_loss : 0.248\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "max_checks_without_progress = 5\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "tf.variables_initializer\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    avg_tr_loss, avg_val_loss = 0, 0\n",
    "    total_batch = int(x_train2.shape[0] / batch_size)\n",
    "    \n",
    "    for step in range(total_batch):\n",
    "        tr_indices = np.random.randint(low = 0, high = x_train2.shape[0], size = batch_size)\n",
    "        val_indices = np.random.randint(low = 0, high = x_valid2.shape[0], size = batch_size)\n",
    "        batch_xs, batch_ys = x_train2[tr_indices], y_train2[tr_indices]\n",
    "        val_xs, val_ys = x_valid2[val_indices], y_valid2[val_indices]\n",
    "        _, tr_loss = adam_opt2.train(x_data = batch_xs, y_data = batch_ys, lr = 1e-3)\n",
    "        val_loss = adam_opt2.evaluate(x_data = val_xs, y_data = val_ys)\n",
    "        \n",
    "        avg_tr_loss += tr_loss / total_batch \n",
    "        avg_val_loss += val_loss / total_batch\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print('step : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(step, tr_loss, val_loss))\n",
    "\n",
    "    print('epoch : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(epoch, avg_tr_loss, avg_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "output_layer의 weight들만 update 한 것이 맞는 지 확인하기위해, update 종료 후 hidden layer의 weight들을\n",
    "가져온다.\n",
    "'''\n",
    "after_hidden_weights = sess.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope ='hidden'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "검증결과 hidden layer의 weight들은 update하지 않았다.\n",
    "'''\n",
    "for num in range(len(before_hidden_weights)):\n",
    "    print(np.all(before_hidden_weights[num] == after_hidden_weights[num]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91853528080641844"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "transfer learning을 한 결과, 5~9를 분류하는 모형의 test accuracy가 향상된다.\n",
    "'''\n",
    "hat = transfer_model1.predict(x_data = x_test2)\n",
    "np.mean(hat == np.argmax(y_test2, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./transfer_model1/transfer_model1.ckpt'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Ch3에서 hidden layer의 weight만 활용하기위해서 5~9를 분류하는 transfer_model1의 hidden layer의 weight들만 저장한다.\n",
    "'''\n",
    "reuse_vars = tf.contrib.framework.get_trainable_variables(scope = 'hidden_layer')\n",
    "saver = tf.train.Saver(var_list = reuse_vars)\n",
    "saver.save(sess = sess, save_path = './transfer_model1/transfer_model1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch3. Transfer learning 2\n",
    "Ch2에서 학습한 transfer_model1의 hidden layer의 weight를 restore하고, 0~9를 분류하는 모형의 output layer의 weight와 Adam optimizer의 parameter의 initial value를 initialize해야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "del transfer_model1, adam_opt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "transfer_model2 = DnnClassifier(sess = sess, n_class = 10, n_features = 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore weights of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./transfer_model1/transfer_model1.ckpt\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "0~4에 대하여 학습한 모형을 restore하면 위의 main_model과 variable_scope가 같으므로,\n",
    "main_model의 weight들에는 pre_trained_model의 weight들의 값이 저장된다.\n",
    "'''\n",
    "reuse_vars = tf.contrib.framework.get_trainable_variables(scope = 'hidden_layer')\n",
    "saver = tf.train.Saver(var_list = reuse_vars)\n",
    "saver.restore(sess = sess, save_path = './transfer_model1/transfer_model1.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Adam solver and initialize weights of output layer and initial parameters of Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden_layer1/dense/kernel:0' shape=(784, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer1/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer2/dense/kernel:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer2/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer3/dense/kernel:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer3/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer4/dense/kernel:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer4/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer5/dense/kernel:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer5/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/kernel:0' shape=(100, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/bias:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "아래의 학습가능한 variable들 중에서 restore하지않은 output_layer의 weight는 값이 들어가있지 않은 상태이다. 추후\n",
    "Adam optimizer의 initial parameter와 같이 initialize한다.\n",
    "'''\n",
    "tf.contrib.framework.get_trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "hidden layer의 weight는 update하지 않으므로 (frozen), output_layer만 update 하기 위해서, update 해야 할\n",
    "variable만 아래처럼 뽑아낼 수 있다. 아래의 list를 Solver의 var_list에 전달한다.\n",
    "'''\n",
    "adam_opt3 = Solver(sess = sess, model = transfer_model2,\n",
    "                    optimizer = tf.train.AdamOptimizer,\n",
    "                    var_list = tf.contrib.framework.get_trainable_variables(scope = 'output_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden_layer1/dense/kernel:0' shape=(784, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer1/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer2/dense/kernel:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer2/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer3/dense/kernel:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer3/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer4/dense/kernel:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer4/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer5/dense/kernel:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer5/dense/bias:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/kernel:0' shape=(100, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/bias:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/kernel/Adam:0' shape=(100, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/kernel/Adam_1:0' shape=(100, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/bias/Adam:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/bias/Adam_1:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "먼저 output_layer의 weight와 Transfer learning을 하는 데에 Adam optimizer를 사용하므로 Adam optimizer의 parameter의 initial value를\n",
    "initialize해야한다. Ch2에서의 과정과 같다.\n",
    "'''\n",
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'output_layer/dense/kernel:0' shape=(100, 10) dtype=float32_ref>, <tf.Variable 'output_layer/dense/bias:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>, <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>, <tf.Variable 'output_layer/dense/kernel/Adam:0' shape=(100, 10) dtype=float32_ref>, <tf.Variable 'output_layer/dense/kernel/Adam_1:0' shape=(100, 10) dtype=float32_ref>, <tf.Variable 'output_layer/dense/bias/Adam:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'output_layer/dense/bias/Adam_1:0' shape=(10,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "vars_params = tf.contrib.framework.get_trainable_variables(scope = 'output_layer') + tf.global_variables()[-6:]\n",
    "print(vars_params)\n",
    "sess.run(tf.variables_initializer(var_list = vars_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :   0, tr_loss : 4.771, val_loss : 4.367\n",
      "step : 100, tr_loss : 0.975, val_loss : 0.854\n",
      "step : 200, tr_loss : 0.518, val_loss : 0.556\n",
      "step : 300, tr_loss : 0.502, val_loss : 0.449\n",
      "step : 400, tr_loss : 0.473, val_loss : 0.457\n",
      "step : 500, tr_loss : 0.441, val_loss : 0.379\n",
      "epoch :   0, tr_loss : 0.734, val_loss : 0.719\n",
      "step :   0, tr_loss : 0.327, val_loss : 0.509\n",
      "step : 100, tr_loss : 0.330, val_loss : 0.315\n",
      "step : 200, tr_loss : 0.581, val_loss : 0.305\n",
      "step : 300, tr_loss : 0.361, val_loss : 0.246\n",
      "step : 400, tr_loss : 0.392, val_loss : 0.321\n",
      "step : 500, tr_loss : 0.227, val_loss : 0.299\n",
      "epoch :   1, tr_loss : 0.346, val_loss : 0.332\n",
      "step :   0, tr_loss : 0.424, val_loss : 0.277\n",
      "step : 100, tr_loss : 0.243, val_loss : 0.334\n",
      "step : 200, tr_loss : 0.306, val_loss : 0.283\n",
      "step : 300, tr_loss : 0.378, val_loss : 0.329\n",
      "step : 400, tr_loss : 0.330, val_loss : 0.380\n",
      "step : 500, tr_loss : 0.306, val_loss : 0.172\n",
      "epoch :   2, tr_loss : 0.299, val_loss : 0.289\n",
      "step :   0, tr_loss : 0.252, val_loss : 0.310\n",
      "step : 100, tr_loss : 0.244, val_loss : 0.214\n",
      "step : 200, tr_loss : 0.384, val_loss : 0.305\n",
      "step : 300, tr_loss : 0.271, val_loss : 0.197\n",
      "step : 400, tr_loss : 0.251, val_loss : 0.229\n",
      "step : 500, tr_loss : 0.116, val_loss : 0.170\n",
      "epoch :   3, tr_loss : 0.276, val_loss : 0.270\n",
      "step :   0, tr_loss : 0.308, val_loss : 0.249\n",
      "step : 100, tr_loss : 0.151, val_loss : 0.272\n",
      "step : 200, tr_loss : 0.213, val_loss : 0.295\n",
      "step : 300, tr_loss : 0.278, val_loss : 0.236\n",
      "step : 400, tr_loss : 0.177, val_loss : 0.216\n",
      "step : 500, tr_loss : 0.273, val_loss : 0.237\n",
      "epoch :   4, tr_loss : 0.263, val_loss : 0.259\n",
      "step :   0, tr_loss : 0.290, val_loss : 0.293\n",
      "step : 100, tr_loss : 0.186, val_loss : 0.269\n",
      "step : 200, tr_loss : 0.266, val_loss : 0.394\n",
      "step : 300, tr_loss : 0.307, val_loss : 0.189\n",
      "step : 400, tr_loss : 0.179, val_loss : 0.189\n",
      "step : 500, tr_loss : 0.191, val_loss : 0.348\n",
      "epoch :   5, tr_loss : 0.253, val_loss : 0.252\n",
      "step :   0, tr_loss : 0.235, val_loss : 0.277\n",
      "step : 100, tr_loss : 0.237, val_loss : 0.134\n",
      "step : 200, tr_loss : 0.230, val_loss : 0.241\n",
      "step : 300, tr_loss : 0.193, val_loss : 0.189\n",
      "step : 400, tr_loss : 0.267, val_loss : 0.253\n",
      "step : 500, tr_loss : 0.245, val_loss : 0.177\n",
      "epoch :   6, tr_loss : 0.247, val_loss : 0.247\n",
      "step :   0, tr_loss : 0.142, val_loss : 0.300\n",
      "step : 100, tr_loss : 0.153, val_loss : 0.221\n",
      "step : 200, tr_loss : 0.176, val_loss : 0.179\n",
      "step : 300, tr_loss : 0.251, val_loss : 0.260\n",
      "step : 400, tr_loss : 0.328, val_loss : 0.200\n",
      "step : 500, tr_loss : 0.215, val_loss : 0.373\n",
      "epoch :   7, tr_loss : 0.242, val_loss : 0.243\n",
      "step :   0, tr_loss : 0.303, val_loss : 0.245\n",
      "step : 100, tr_loss : 0.264, val_loss : 0.256\n",
      "step : 200, tr_loss : 0.360, val_loss : 0.291\n",
      "step : 300, tr_loss : 0.301, val_loss : 0.327\n",
      "step : 400, tr_loss : 0.248, val_loss : 0.339\n",
      "step : 500, tr_loss : 0.147, val_loss : 0.235\n",
      "epoch :   8, tr_loss : 0.238, val_loss : 0.240\n",
      "step :   0, tr_loss : 0.204, val_loss : 0.295\n",
      "step : 100, tr_loss : 0.323, val_loss : 0.270\n",
      "step : 200, tr_loss : 0.147, val_loss : 0.174\n",
      "step : 300, tr_loss : 0.229, val_loss : 0.323\n",
      "step : 400, tr_loss : 0.329, val_loss : 0.268\n",
      "step : 500, tr_loss : 0.190, val_loss : 0.172\n",
      "epoch :   9, tr_loss : 0.235, val_loss : 0.238\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "max_checks_without_progress = 5\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    avg_tr_loss, avg_val_loss = 0, 0\n",
    "    total_batch = int(mnist.train.images.shape[0] / batch_size)\n",
    "    \n",
    "    for step in range(total_batch):\n",
    "    \n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size = batch_size)\n",
    "        val_xs, val_ys = mnist.validation.next_batch(batch_size = batch_size)\n",
    "        _, tr_loss = adam_opt3.train(x_data = batch_xs, y_data = batch_ys, lr = 1e-3)\n",
    "        val_loss = adam_opt3.evaluate(x_data = val_xs, y_data = val_ys)\n",
    "        \n",
    "        avg_tr_loss += tr_loss / total_batch \n",
    "        avg_val_loss += val_loss / total_batch\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print('step : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(step, tr_loss, val_loss))\n",
    "\n",
    "    print('epoch : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(epoch, avg_tr_loss, avg_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 92.03%\n"
     ]
    }
   ],
   "source": [
    "hat = transfer_model2.predict(x_data = mnist.test.images)\n",
    "print('test accuracy : {:.2%}'.format(np.mean(hat == np.argmax(mnist.test.labels, axis = 1))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
