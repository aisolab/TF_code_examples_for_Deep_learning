{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial of implementing Batch normalization\n",
    "mnist image를 분류하는 Convolution Neural Network에 Batch normalization을 적용하는 간단한 example\n",
    "\n",
    "Batch normalization paper : http://proceedings.mlr.press/v37/ioffe15.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import shutil \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.examples.tutorials.mnist import input_data # load mnist dataset\n",
    "mnist = input_data.read_data_sets(train_dir = './MNIST_data', one_hot = True, reshape = True, seed = 20171104)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define MnistCNN class\n",
    "conv-conv-max pool-conv-conv-max pool-fc-fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Batch normalization의 구현을 위해서는 tf.layers module에 있는 tf.layers.batch_normalization을 활용한다. activation 하기전에\n",
    "Batch normalization을 하고, 후에 activation을 한다.(전에하냐 후에하냐라는 issue가 있으나 activation 전에 하는 것이 convention이고\n",
    "실험결과로 activation 전에 하는 것이 좋다는 결과도 종종 보인다.)\n",
    "'''\n",
    "class MnistCNN:\n",
    "    def __init__(self, activation_fn = tf.nn.relu, initializer = tf.contrib.layers.variance_scaling_initializer(),\n",
    "                 l2_scale = 0.02):\n",
    "        \n",
    "        with tf.variable_scope('input_layer'):\n",
    "            self._x = tf.placeholder(dtype = tf.float32, shape = [None,784])\n",
    "            self._ximg = tf.reshape(tensor = self._x, shape = [-1,28,28,1])\n",
    "            self._y = tf.placeholder(dtype = tf.float32, shape = [None,10])\n",
    "            self._training = tf.placeholder(dtype = tf.bool)\n",
    "            \n",
    "        with tf.variable_scope('conv_layer1'):\n",
    "            _conv_pre = tf.layers.conv2d(inputs = self._ximg, filters = 64, kernel_size = [3,3],\n",
    "                                        kernel_initializer = initializer,\n",
    "                                        kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale),\n",
    "                                        padding = 'same')\n",
    "            _conv_bn = tf.layers.batch_normalization(inputs = _conv_pre, momentum = .9, training = self._training)\n",
    "            _conv_relu = activation_fn(_conv_bn)\n",
    "            \n",
    "        with tf.variable_scope('conv_layer2'):\n",
    "            _conv_pre = tf.layers.conv2d(inputs = _conv_relu, filters = 64, kernel_size = [3,3],\n",
    "                                        kernel_initializer = initializer,\n",
    "                                        kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale),\n",
    "                                        padding = 'same')\n",
    "            _conv_bn = tf.layers.batch_normalization(inputs = _conv_pre, momentum = .9, training = self._training)\n",
    "            _conv_relu = activation_fn(_conv_bn)\n",
    "            \n",
    "        with tf.variable_scope('max_pool1'):\n",
    "            _pooled = tf.layers.max_pooling2d(inputs = _conv_relu, pool_size = [2,2], strides = 2)\n",
    "            \n",
    "        with tf.variable_scope('conv_layer3'):\n",
    "            _conv_pre = tf.layers.conv2d(inputs = _pooled, filters = 128, kernel_size = [3,3],\n",
    "                                        kernel_initializer = initializer,\n",
    "                                        kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale),\n",
    "                                        padding = 'same')\n",
    "            _conv_bn = tf.layers.batch_normalization(inputs = _conv_pre, momentum = .9, training = self._training)\n",
    "            _conv_relu = activation_fn(_conv_bn)\n",
    "            \n",
    "        with tf.variable_scope('conv_layer4'):\n",
    "            _conv_pre = tf.layers.conv2d(inputs = _conv_relu, filters = 128, kernel_size = [3,3],\n",
    "                                        kernel_initializer = initializer,\n",
    "                                        kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale),\n",
    "                                        padding = 'same')\n",
    "            _conv_bn = tf.layers.batch_normalization(inputs = _conv_pre, momentum = .9, training = self._training)\n",
    "            _conv_relu = activation_fn(_conv_bn)\n",
    "            \n",
    "        with tf.variable_scope('max_pool2'):\n",
    "            _pooled = tf.layers.max_pooling2d(inputs = _conv_relu, pool_size = [2,2], strides = 2)\n",
    "        \n",
    "        with tf.variable_scope('dense_layer1'):\n",
    "            _pooled_vector = tf.reshape(tensor = _pooled, shape = [-1,np.cumprod(_pooled.get_shape().as_list()[-3:])[-1]])\n",
    "            _fc_pre = tf.layers.dense(inputs = _pooled_vector, units = 1024, kernel_initializer = initializer,\n",
    "                                  kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale))\n",
    "            _fc_bn = tf.layers.batch_normalization(inputs = _fc_pre, momentum = .9, training = self._training)\n",
    "            _fc_relu = activation_fn(_fc_bn)\n",
    "            \n",
    "        with tf.variable_scope('output_layer'):\n",
    "            self._score = tf.layers.dense(inputs = _fc_relu, units = 10, kernel_initializer = initializer,\n",
    "                                          kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale))\n",
    "            \n",
    "        with tf.variable_scope('loss'):\n",
    "            _ce_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = self._score, labels = self._y))\n",
    "            _reg_term = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "            self._total_loss = _ce_loss +  _reg_term\n",
    "        ''' \n",
    "           각각 mini_batch 마다의 mean과 variance를 계산하고, 이를 Exponential Moving Average로 저장하는 과정이 필요한 데,\n",
    "           이를 수행하기위해 tf.get_collection(tf.GraphKeys.UPDATE_OPS)에서 뽑히는 ops를 저장해둔다. 이 op들은 후에\n",
    "           tf.control_dependencies의 control_inputs argument에 전달된다.\n",
    "           \n",
    "           Note: when training, the moving_mean and moving_variance need to be updated.\n",
    "           By default the update ops are placed in `tf.GraphKeys.UPDATE_OPS`, so they\n",
    "           need to be added as a dependency to the `train_op`. For example:\n",
    "\n",
    "                \n",
    "               update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) <-- 본 example에서는 model 생성 class 코드에 들어가고,\n",
    "                                                                           객체변수로 저장한다.\n",
    "               \n",
    "               with tf.control_dependencies(update_ops): <-- Solver class는 코드에 들어간다. Solver class는 model class\n",
    "                   train_op = optimizer.minimize(loss)      생성된 instance를 input으로 받으므로, 거기에서 객체변수로 \n",
    "                                                             저장된 update_ops를 tf.control_dependencies의 argument에 전달한다.\n",
    "        '''\n",
    "        # 객체변수에 model class 코드로 생성되는 graph의 UPDATE_OPS를 저장\n",
    "        self._update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) \n",
    "        \n",
    "        with tf.variable_scope('predict'):\n",
    "            self._prediction = tf.argmax(input = self._score, axis = 1)\n",
    "    \n",
    "    def predict(self, sess, x_data, training):\n",
    "        feed_predict = {self._x : x_data, self._training : training}\n",
    "        return sess.run(fetches = self._prediction, feed_dict = feed_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Solver class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver:\n",
    "    def __init__(self, model, optimizer = tf.train.AdamOptimizer, var_list = None):\n",
    "        self._model = model\n",
    "        self._lr = tf.placeholder(dtype = tf.float32)\n",
    "        self._optimizer = optimizer(learning_rate = self._lr)\n",
    "        \n",
    "        # Solver class는 model class로부터 생성된 instance를 input으로 받음. model class에서 저장한 객체변수를 아래와 같이 활용\n",
    "        with tf.control_dependencies(self._model._update_ops):\n",
    "            self._training_op = self._optimizer.minimize(loss = self._model._total_loss, var_list = var_list)\n",
    "    \n",
    "    def train(self, sess, x_data, y_data, lr, training):\n",
    "        feed_train = {self._model._x : x_data, self._model._y : y_data, self._lr : lr,\n",
    "                      self._model._training : training}\n",
    "        return sess.run(fetches = [self._training_op, self._model._total_loss], feed_dict = feed_train)\n",
    "            \n",
    "    def evaluate(self, sess, x_data, y_data, training = False):\n",
    "        feed_loss = {self._model._x : x_data, self._model._y : y_data, self._model._training : training}\n",
    "        return sess.run(fetches = self._model._total_loss, feed_dict = feed_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate CNN model and Adam solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "mnist_classifier = MnistCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_solver = Solver(model = mnist_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "batch_size = 100\n",
    "n_epochs = 10\n",
    "best_loss = np.infty\n",
    "max_checks_without_progress = 15\n",
    "checks_without_progress = 0\n",
    "tr_loss_history = []\n",
    "val_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :   0, tr_loss : 31.353, val_loss : 31.285\n",
      "step : 100, tr_loss : 3.589, val_loss : 3.813\n",
      "step : 200, tr_loss : 1.709, val_loss : 1.768\n",
      "step : 300, tr_loss : 0.953, val_loss : 1.186\n",
      "step : 400, tr_loss : 0.780, val_loss : 0.795\n",
      "step : 500, tr_loss : 0.626, val_loss : 0.742\n",
      "epoch :   0, tr_loss : 2.976, val_loss : 3.082\n",
      "step :   0, tr_loss : 0.648, val_loss : 0.786\n",
      "step : 100, tr_loss : 0.583, val_loss : 0.452\n",
      "step : 200, tr_loss : 0.502, val_loss : 0.606\n",
      "step : 300, tr_loss : 0.518, val_loss : 0.511\n",
      "step : 400, tr_loss : 0.351, val_loss : 0.486\n",
      "step : 500, tr_loss : 0.421, val_loss : 0.838\n",
      "epoch :   1, tr_loss : 0.474, val_loss : 0.632\n",
      "step :   0, tr_loss : 0.396, val_loss : 0.461\n",
      "step : 100, tr_loss : 0.344, val_loss : 0.486\n",
      "step : 200, tr_loss : 0.316, val_loss : 0.496\n",
      "step : 300, tr_loss : 0.366, val_loss : 0.355\n",
      "step : 400, tr_loss : 0.364, val_loss : 0.335\n",
      "step : 500, tr_loss : 0.376, val_loss : 0.603\n",
      "epoch :   2, tr_loss : 0.364, val_loss : 0.448\n",
      "step :   0, tr_loss : 0.592, val_loss : 0.388\n",
      "step : 100, tr_loss : 0.391, val_loss : 0.604\n",
      "step : 200, tr_loss : 0.426, val_loss : 0.339\n",
      "step : 300, tr_loss : 0.389, val_loss : 0.287\n",
      "step : 400, tr_loss : 0.257, val_loss : 0.345\n",
      "step : 500, tr_loss : 0.313, val_loss : 0.366\n",
      "epoch :   3, tr_loss : 0.320, val_loss : 0.393\n",
      "step :   0, tr_loss : 0.352, val_loss : 0.254\n",
      "step : 100, tr_loss : 0.319, val_loss : 0.268\n",
      "step : 200, tr_loss : 0.358, val_loss : 0.435\n",
      "step : 300, tr_loss : 0.229, val_loss : 0.452\n",
      "step : 400, tr_loss : 0.243, val_loss : 0.381\n",
      "step : 500, tr_loss : 0.192, val_loss : 0.395\n",
      "epoch :   4, tr_loss : 0.276, val_loss : 0.332\n",
      "step :   0, tr_loss : 0.272, val_loss : 0.322\n",
      "step : 100, tr_loss : 0.446, val_loss : 0.312\n",
      "step : 200, tr_loss : 0.223, val_loss : 0.280\n",
      "step : 300, tr_loss : 0.168, val_loss : 0.239\n",
      "step : 400, tr_loss : 0.179, val_loss : 0.321\n",
      "step : 500, tr_loss : 0.243, val_loss : 0.319\n",
      "epoch :   5, tr_loss : 0.251, val_loss : 0.288\n",
      "step :   0, tr_loss : 0.334, val_loss : 0.202\n",
      "step : 100, tr_loss : 0.243, val_loss : 0.193\n",
      "step : 200, tr_loss : 0.256, val_loss : 0.221\n",
      "step : 300, tr_loss : 0.181, val_loss : 0.186\n",
      "step : 400, tr_loss : 0.252, val_loss : 0.206\n",
      "step : 500, tr_loss : 0.191, val_loss : 0.181\n",
      "epoch :   6, tr_loss : 0.227, val_loss : 0.245\n",
      "step :   0, tr_loss : 0.252, val_loss : 0.255\n",
      "step : 100, tr_loss : 0.227, val_loss : 0.261\n",
      "step : 200, tr_loss : 0.179, val_loss : 0.192\n",
      "step : 300, tr_loss : 0.169, val_loss : 0.194\n",
      "step : 400, tr_loss : 0.265, val_loss : 0.203\n",
      "step : 500, tr_loss : 0.227, val_loss : 0.205\n",
      "epoch :   7, tr_loss : 0.201, val_loss : 0.219\n",
      "step :   0, tr_loss : 0.211, val_loss : 0.216\n",
      "step : 100, tr_loss : 0.227, val_loss : 0.174\n",
      "step : 200, tr_loss : 0.217, val_loss : 0.194\n",
      "step : 300, tr_loss : 0.224, val_loss : 0.180\n",
      "step : 400, tr_loss : 0.189, val_loss : 0.241\n",
      "step : 500, tr_loss : 0.147, val_loss : 0.411\n",
      "epoch :   8, tr_loss : 0.196, val_loss : 0.216\n",
      "step :   0, tr_loss : 0.213, val_loss : 0.145\n",
      "step : 100, tr_loss : 0.155, val_loss : 0.171\n",
      "step : 200, tr_loss : 0.209, val_loss : 0.164\n",
      "step : 300, tr_loss : 0.158, val_loss : 0.226\n",
      "step : 400, tr_loss : 0.156, val_loss : 0.218\n",
      "step : 500, tr_loss : 0.229, val_loss : 0.234\n",
      "epoch :   9, tr_loss : 0.182, val_loss : 0.192\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    avg_tr_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for step in range(total_batch):\n",
    "        \n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size = batch_size)\n",
    "        val_xs, val_ys = mnist.validation.next_batch(batch_size = batch_size)\n",
    "        _, tr_loss = adam_solver.train(sess = sess, x_data = batch_xs, y_data = batch_ys, lr = 1e-3, training = True)\n",
    "        val_loss = adam_solver.evaluate(sess = sess, x_data = val_xs, y_data = val_ys)\n",
    "        \n",
    "        avg_tr_loss += tr_loss / total_batch\n",
    "        avg_val_loss += val_loss / total_batch\n",
    "        if step % 100 == 0:\n",
    "            print('step : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(step, tr_loss, val_loss))\n",
    "    \n",
    "    print('epoch : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(epoch, avg_tr_loss, avg_val_loss))\n",
    "    tr_loss_history.append(avg_tr_loss)\n",
    "    val_loss_history.append(avg_val_loss)\n",
    "    \n",
    "     # early stopping\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_loss = avg_val_loss\n",
    "        checks_without_progress = 0\n",
    "    else:\n",
    "        checks_without_progress += 1\n",
    "        if checks_without_progress > max_checks_without_progress:\n",
    "            print('Early stopping')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1fee2368e10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fee229d6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_history, label = 'train')\n",
    "plt.plot(val_loss_history, label = 'validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat = mnist_classifier.predict(sess=sess, x_data=mnist.test.images, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 95.48%\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : {:.2%}'.format(np.mean(np.argmax(mnist.test.labels, axis = 1) == hat)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
