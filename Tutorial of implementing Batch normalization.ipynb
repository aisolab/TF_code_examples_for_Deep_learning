{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial of implementing Batch normalization\n",
    "mnist image를 분류하는 Convolution Neural Network에 Batch normalization을 적용하는 간단한 example\n",
    "\n",
    "Batch normalization paper : http://proceedings.mlr.press/v37/ioffe15.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import shutil \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.examples.tutorials.mnist import input_data # load mnist dataset\n",
    "mnist = input_data.read_data_sets(train_dir = './MNIST_data', one_hot = True, reshape = True, seed = 20171104)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define MnistCNN class\n",
    "conv-conv-max pool-conv-conv-max pool-fc-fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Batch normalization의 구현을 위해서는 tf.layers module에 있는 tf.layers.batch_normalization을 활용한다. activation 하기전에\n",
    "Batch normalization을 하고, 후에 activation을 한다.(전에하냐 후에하냐라는 issue가 있으나 activation 전에 하는 것이 convention이고\n",
    "실험결과로 activation 전에 하는 것이 좋다는 결과도 종종 보인다.)\n",
    "'''\n",
    "class MnistCNN:\n",
    "    def __init__(self, activation_fn = tf.nn.relu, initializer = tf.contrib.layers.variance_scaling_initializer(),\n",
    "                 l2_scale = .5):\n",
    "        \n",
    "        with tf.variable_scope('input_layer'):\n",
    "            self._x = tf.placeholder(dtype = tf.float32, shape = [None,784])\n",
    "            self._ximg = tf.reshape(tensor = self._x, shape = [-1,28,28,1])\n",
    "            self._y = tf.placeholder(dtype = tf.float32, shape = [None,10])\n",
    "            self._training = tf.placeholder(dtype = tf.bool)\n",
    "            \n",
    "        with tf.variable_scope('conv_layer1'):\n",
    "            _conv_pre = tf.layers.conv2d(inputs = self._ximg, filters = 64, kernel_size = [3,3],\n",
    "                                        kernel_initializer = initializer,\n",
    "                                        kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale),\n",
    "                                        padding = 'same')\n",
    "            _conv_bn = tf.layers.batch_normalization(inputs = _conv_pre, momentum = .9, training = self._training)\n",
    "            _conv_relu = activation_fn(_conv_bn)\n",
    "            \n",
    "        with tf.variable_scope('conv_layer2'):\n",
    "            _conv_pre = tf.layers.conv2d(inputs = _conv_relu, filters = 64, kernel_size = [3,3],\n",
    "                                        kernel_initializer = initializer,\n",
    "                                        kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale),\n",
    "                                        padding = 'same')\n",
    "            _conv_bn = tf.layers.batch_normalization(inputs = _conv_pre, momentum = .9, training = self._training)\n",
    "            _conv_relu = activation_fn(_conv_bn)\n",
    "            \n",
    "        with tf.variable_scope('max_pool1'):\n",
    "            _pooled = tf.layers.max_pooling2d(inputs = _conv_relu, pool_size = [2,2], strides = 2)\n",
    "            \n",
    "        with tf.variable_scope('conv_layer3'):\n",
    "            _conv_pre = tf.layers.conv2d(inputs = _pooled, filters = 128, kernel_size = [3,3],\n",
    "                                        kernel_initializer = initializer,\n",
    "                                        kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale),\n",
    "                                        padding = 'same')\n",
    "            _conv_bn = tf.layers.batch_normalization(inputs = _conv_pre, momentum = .9, training = self._training)\n",
    "            _conv_relu = activation_fn(_conv_bn)\n",
    "            \n",
    "        with tf.variable_scope('conv_layer4'):\n",
    "            _conv_pre = tf.layers.conv2d(inputs = _conv_relu, filters = 128, kernel_size = [3,3],\n",
    "                                        kernel_initializer = initializer,\n",
    "                                        kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale),\n",
    "                                        padding = 'same')\n",
    "            _conv_bn = tf.layers.batch_normalization(inputs = _conv_pre, momentum = .9, training = self._training)\n",
    "            _conv_relu = activation_fn(_conv_bn)\n",
    "            \n",
    "        with tf.variable_scope('max_pool2'):\n",
    "            _pooled = tf.layers.max_pooling2d(inputs = _conv_relu, pool_size = [2,2], strides = 2)\n",
    "        \n",
    "        with tf.variable_scope('dense_layer1'):\n",
    "            _pooled_vector = tf.reshape(tensor = _pooled, shape = [-1,np.cumprod(_pooled.get_shape().as_list()[-3:])[-1]])\n",
    "            _fc_pre = tf.layers.dense(inputs = _pooled_vector, units = 1024, kernel_initializer = initializer,\n",
    "                                  kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale))\n",
    "            _fc_bn = tf.layers.batch_normalization(inputs = _fc_pre, momentum = .9, training = self._training)\n",
    "            _fc_relu = activation_fn(_fc_bn)\n",
    "            \n",
    "        with tf.variable_scope('output_layer'):\n",
    "            self._score = tf.layers.dense(inputs = _fc_relu, units = 10, kernel_initializer = initializer,\n",
    "                                          kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale))\n",
    "            \n",
    "        with tf.variable_scope('loss'):\n",
    "            self._ce_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = self._score, labels = self._y))\n",
    "        ''' \n",
    "           각각 mini_batch 마다의 mean과 variance를 계산하고, 이를 Exponential Moving Average로 저장하는 과정이 필요한 데,\n",
    "           이를 수행하기위해 tf.get_collection(tf.GraphKeys.UPDATE_OPS)에서 뽑히는 ops를 저장해둔다. 이 op들은 후에\n",
    "           tf.control_dependencies의 control_inputs argument에 전달된다.\n",
    "           \n",
    "           Note: when training, the moving_mean and moving_variance need to be updated.\n",
    "           By default the update ops are placed in `tf.GraphKeys.UPDATE_OPS`, so they\n",
    "           need to be added as a dependency to the `train_op`. For example:\n",
    "\n",
    "                \n",
    "               update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) <-- 본 example에서는 model 생성 class 코드에 들어가고,\n",
    "                                                                           객체변수로 저장한다.\n",
    "               \n",
    "               with tf.control_dependencies(update_ops): <-- Solver class는 코드에 들어간다. Solver class는 model class\n",
    "                   train_op = optimizer.minimize(loss)      생성된 instance를 input으로 받으므로, 거기에서 객체변수로 \n",
    "                                                             저장된 update_ops를 tf.control_dependencies의 argument에 전달한다.\n",
    "        '''\n",
    "        # 객체변수에 model class 코드로 생성되는 graph의 UPDATE_OPS를 저장\n",
    "        self._update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) \n",
    "        \n",
    "        with tf.variable_scope('predict'):\n",
    "            self._prediction = tf.argmax(input = self._score, axis = 1)\n",
    "    \n",
    "    def predict(self, sess, x_data, training):\n",
    "        feed_predict = {self._x : x_data, self._training : training}\n",
    "        return sess.run(fetches = self._prediction, feed_dict = feed_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Solver class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver:\n",
    "    def __init__(self, model, optimizer = tf.train.AdamOptimizer, var_list = None):\n",
    "        self._model = model\n",
    "        self._lr = tf.placeholder(dtype = tf.float32)\n",
    "        self._optimizer = optimizer(learning_rate = self._lr)\n",
    "        \n",
    "        # Solver class는 model class로부터 생성된 instance를 input으로 받음. model class에서 저장한 객체변수를 아래와 같이 활용\n",
    "        with tf.control_dependencies(self._model._update_ops):\n",
    "            self._training_op = self._optimizer.minimize(loss = self._model._ce_loss, var_list = var_list)\n",
    "    \n",
    "    def train(self, sess, x_data, y_data, lr, training):\n",
    "        feed_train = {self._model._x : x_data, self._model._y : y_data, self._lr : lr,\n",
    "                      self._model._training : training}\n",
    "        return sess.run(fetches = [self._training_op, self._model._ce_loss], feed_dict = feed_train)\n",
    "            \n",
    "    def evaluate(self, sess, x_data, y_data, training = False):\n",
    "        feed_loss = {self._model._x : x_data, self._model._y : y_data, self._model._training : training}\n",
    "        return sess.run(fetches = self._model._ce_loss, feed_dict = feed_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate CNN model and Adam solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "mnist_classifier = MnistCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_solver = Solver(model = mnist_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "batch_size = 100\n",
    "n_epochs = 3\n",
    "best_loss = np.infty\n",
    "max_checks_without_progress = 15\n",
    "checks_without_progress = 0\n",
    "tr_loss_history = []\n",
    "val_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :   0, tr_loss : 2.832, val_loss : 4.031\n",
      "epoch :   0, tr_loss : 0.288, val_loss : 0.613\n",
      "step :   0, tr_loss : 0.148, val_loss : 0.054\n",
      "epoch :   1, tr_loss : 0.093, val_loss : 0.116\n",
      "step :   0, tr_loss : 0.059, val_loss : 0.085\n",
      "epoch :   2, tr_loss : 0.089, val_loss : 0.109\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    avg_tr_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    total_batch = int(5000 / batch_size)\n",
    "    \n",
    "    for step in range(total_batch):\n",
    "        \n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size = batch_size)\n",
    "        val_xs, val_ys = mnist.validation.next_batch(batch_size = batch_size)\n",
    "        _, tr_loss = adam_solver.train(sess = sess, x_data = batch_xs, y_data = batch_ys, lr = 1e-3, training = True)\n",
    "        val_loss = adam_solver.evaluate(sess = sess, x_data = val_xs, y_data = val_ys)\n",
    "        \n",
    "        avg_tr_loss += tr_loss / total_batch\n",
    "        avg_val_loss += val_loss / total_batch\n",
    "        if step % 100 == 0:\n",
    "            print('step : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(step, tr_loss, val_loss))\n",
    "    \n",
    "    print('epoch : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(epoch, avg_tr_loss, avg_val_loss))\n",
    "    tr_loss_history.append(avg_tr_loss)\n",
    "    val_loss_history.append(avg_val_loss)\n",
    "    \n",
    "     # early stopping\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_loss = avg_val_loss\n",
    "        checks_without_progress = 0\n",
    "    else:\n",
    "        checks_without_progress += 1\n",
    "        if checks_without_progress > max_checks_without_progress:\n",
    "            print('Early stopping')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23d7359ef98>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKRWE/j+CnMOwRNcozgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23d6f2399e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_history, label = 'train')\n",
    "plt.plot(val_loss_history, label = 'validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat = mnist_classifier.predict(sess=sess, x_data=mnist.test.images, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 96.84%\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : {:.2%}'.format(np.mean(np.argmax(mnist.test.labels, axis = 1) == hat)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
