{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial of implementing Batch normalization and Drop out\n",
    "fashion mnist image를 분류하는 Convolution Neural Network에 Batch normalization과 Drop out을 동시 적용하는 간단한 example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Fashion-mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Fashion-mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'T-shirt/top',\n",
       " 1: 'Trouser',\n",
       " 2: 'Pullover',\n",
       " 3: 'Dress',\n",
       " 4: 'Coat',\n",
       " 5: 'Sandal',\n",
       " 6: 'Shirt',\n",
       " 7: 'Sneaker',\n",
       " 8: 'Bag',\n",
       " 9: 'Ankle boot'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_set = {0 : 'T-shirt/top', 1 : 'Trouser', 2 : 'Pullover',\n",
    "             3 : 'Dress', 4 : 'Coat', 5 : 'Sandal', 6 : 'Shirt',\n",
    "             7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle boot'}\n",
    "label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[55000:].reshape(-1,28,28,1)\n",
    "y_val = y_train[55000:]\n",
    "x_train = x_train[:55000].reshape(-1,28,28,1)\n",
    "y_train = y_train[:55000]   \n",
    "x_test = x_test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, y_train, y_test = sess.run([tf.one_hot(y_val, depth = 10), tf.one_hot(y_train, depth = 10), tf.one_hot(y_test, depth = 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Ankle boot')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFRNJREFUeJzt3Xuw3GV9x/H3x3DNxYQQQi5EwiXU\n2BZDjYHKZUAEgT8ABaJMR8MoxrE6rR2dkVqn0LEWijeclrETgYKDYpkRKg43KWMHnXA7MDSJBDWE\nACcJJ0C4JCEQknz7x/6i6/H8nufk7J7dDc/nNXPm7O73PLvP7jmfs5fn9zyPIgIzK8/but0BM+sO\nh9+sUA6/WaEcfrNCOfxmhXL4zQrl8L/FSQpJR+5uLXOdF0n6Zeu9s25y+PcQkv5X0kuS9u12X0aL\npJMl9Xe7H6Vw+PcAkmYDJwIBnN3VzthbhsO/Z/g48ABwPbCouSDpeklXS7pd0iZJD0o6YqgrkXSC\npGclnTJEbV9J35D0jKQBSf8haf9EnyTp3yS9IukJSac2FWZIuk3SRkmrJH1q0O1cJWld9XVVddk4\n4E5ghqTN1deM3XqUbLc4/HuGjwM/qL4+KOngQfULgX8CDgBWAV8bfAWSPgjcBJwXET8f4jb+FTgK\nmAccCcwE/jHRp2OB1cAU4FLgFkmTq9pNQD8wAzgf+Jemfw7/ABxX3c67gQXAVyJiC3AmsC4ixldf\n6xK3b62KCH/18BdwAvAmMKU6/wTwd03164Frms6fBTzRdD6AvweeBv580HUHjaAL2AIc0VT7S+Cp\nmj5dBKwD1HTZQ8DHgFnADmBCU+1y4Prq9JPAWU21DwJrqtMnA/3dfsxL+fIzf+9bBPwsIl6ozv+Q\nQS/9geeaTr8GjB9U/zxwc0Qsr7mNg4CxwCOSXpb0MnBXdXmdtVEltvI0jWf6GcDGiNg0qDazOj2j\nOj+4nXXYXt3ugNWr3nMvBMZI2hXwfYFJkt4dEf83zKu6ALhW0tqIuGqI+gvAVuBPI2LtMK9zpiQ1\n/QN4B3AbjVcEkyVNaPoH8A5g1/WuAw4FftVU2/Xy3lNMO8jP/L3tXBovod9F4z3yPGAu8AsanwMM\n1zrgVOBvJP314GJE7AS+B3xb0lQASTOrzwnqTK2ub29JF1T9uiMingWWApdL2k/S0cAnaXxeAY3P\nA74i6SBJU2h8rnBjVRsADpQ0cTfum42Qw9/bFgH/GRHPRMRzu76Afwf+StKwX7lFxDM0/gF8SdLF\nQ/zIl2h8WPiApFeB/wH+JHGVDwJzaLxq+BpwfkS8WNUuBGbT+KdzK3BpRNxT1f4Z6AOWAcuBR6vL\niIgnaPxzWF29/fDbgVGkP3zbZmal8DO/WaEcfrNCOfxmhXL4zQrV0XF+Sf500WyURYSG83MtPfNL\nOkPSr6vJG5e0cl1m1lkjHuqTNAb4DXAajUkcDwMXRsTjiTZ+5jcbZZ145l8ArIqI1RGxDfgRcE4L\n12dmHdRK+GcCzzad7+f3kzd+R9JiSX2S+lq4LTNrs1Y+8BvqpcUfvayPiCXAEvDLfrNe0sozfz+N\nudu7HMLvZ2eZWY9rJfwPA3MkHSZpH+CjNKZ0mtkeYMQv+yNiu6TPAXcDY4DrIuJXmWZm1iM6OqvP\n7/nNRl9HDvIxsz2Xw29WKIffrFAOv1mhHH6zQjn8ZoVy+M0K5fCbFcrhNyuUw29WKIffrFAOv1mh\nHH6zQnmL7rc4KT3Bq9VZnRMmTEjWTzjhhNranXfe2dJt5+7bmDFjamvbt29v6bZblet7Srtm4vqZ\n36xQDr9ZoRx+s0I5/GaFcvjNCuXwmxXK4TcrlMf53+Le9rb0//cdO3Yk60ceeWSyfvHFFyfrW7du\nra1t2bIl2fb1119P1h966KFkvZWx/Nw4fO5xzbVvpW+p4xdyv89mfuY3K5TDb1Yoh9+sUA6/WaEc\nfrNCOfxmhXL4zQrlcf63uNSYMOTHhd///vcn6x/4wAeS9f7+/travvvum2w7duzYZP20005L1q+5\n5pra2sDAQLJtbs787oynD2X8+PG1tZ07dybbvvbaay3d9i4thV/SGmATsAPYHhHz29EpMxt97Xjm\nPyUiXmjD9ZhZB/k9v1mhWg1/AD+T9IikxUP9gKTFkvok9bV4W2bWRq2+7D8+ItZJmgrcI+mJiLiv\n+QciYgmwBEBSe1YeNLOWtfTMHxHrqu8bgFuBBe3olJmNvhGHX9I4SRN2nQZOB1a0q2NmNrpaedl/\nMHBrNW95L+CHEXFXW3plbbNt27aW2r/3ve9N1mfPnp2sp44zyM2Jv/vuu5P1Y445Jlm/8sora2t9\nfemPoJYvX56sr1y5MllfsCD9Ijj1uC5dujTZ9v7776+tbd68Odm22YjDHxGrgXePtL2ZdZeH+swK\n5fCbFcrhNyuUw29WKIffrFBq13a/w7oxH+E3KlLLROd+v7lpsanhMoBJkyYl62+++WZtLTd1Nefh\nhx9O1letWlVba3UIdPr06cl66n5Duu/nn39+su3VV19dW+vr6+PVV18d1v7ffuY3K5TDb1Yoh9+s\nUA6/WaEcfrNCOfxmhXL4zQrlcf4ekNvOuRW53+8DDzyQrOem7Oak7ltum+pWx+JTW3znjjF49NFH\nk/XUMQSQv29nnHFGbe3www9Ptp05c2ayHhEe5zezeg6/WaEcfrNCOfxmhXL4zQrl8JsVyuE3K5S3\n6O4BnTzWYrCXXnopWc/NW9+6dWuyntqGe6+90n9+qW2sIT2OD7D//vvX1nLj/CeeeGKy/r73vS9Z\nzy1LPnXq1NraXXd1ZgV8P/ObFcrhNyuUw29WKIffrFAOv1mhHH6zQjn8ZoXyOH/hxo4dm6znxqtz\n9ddee6229sorryTbvvjii8l6bq2B1PETuTUUcvcr97jt2LEjWU8dZzBr1qxk23bJPvNLuk7SBkkr\nmi6bLOkeSb+tvh8wut00s3Ybzsv+64HBy45cAtwbEXOAe6vzZrYHyYY/Iu4DNg66+Bzghur0DcC5\nbe6XmY2ykb7nPzgi1gNExHpJtQcqS1oMLB7h7ZjZKBn1D/wiYgmwBLyAp1kvGelQ34Ck6QDV9w3t\n65KZdcJIw38bsKg6vQj4SXu6Y2adkn3ZL+km4GRgiqR+4FLgCuBmSZ8EngEuGM1OvtW1OuacGlPO\nzYmfMWNGsv7GG2+0VE/N58+ty586RgBg0qRJyXrqOIHcOP0+++yTrG/atClZnzhxYrK+bNmy2lru\ndzZ//vza2uOPP55s2ywb/oi4sKZ06rBvxcx6jg/vNSuUw29WKIffrFAOv1mhHH6zQnlKbw/ILd09\nZsyYZD011PeRj3wk2XbatGnJ+vPPP5+sp5bHhvTU1XHjxiXb5qa25oYKU8OMb775ZrJtblnx3P0+\n8MADk/Wrr766tjZv3rxk21Tfdme7dz/zmxXK4TcrlMNvViiH36xQDr9ZoRx+s0I5/GaFUie3h/ZK\nPkPLjSlv3759xNd97LHHJuu33357sp7bgruVYxAmTJiQbJvbgju3tPfee+89ohrkj0HIbW2ek7pv\nX//615Ntb7zxxmQ9IoY12O9nfrNCOfxmhXL4zQrl8JsVyuE3K5TDb1Yoh9+sUHvUfP7UXOXceHNu\n+evcPOjU/O/UnPXhaGUcP+eOO+5I1rds2ZKs58b5c0tcp44jya0VkPud7rfffsl6bs5+K21zv/Nc\n348++ujaWm7r8nbxM79ZoRx+s0I5/GaFcvjNCuXwmxXK4TcrlMNvVqieGudvZW74aI6Vj7aTTjop\nWT/vvPOS9eOPP762ltvmOjcnPjeOn1uLIPU7y/Ut9/eQWpcf0scB5NaxyPUtJ/e4bd68ubb24Q9/\nONn2pz/96Yj6NFj2mV/SdZI2SFrRdNllktZKeqz6OqstvTGzjhnOy/7rgTOGuPzbETGv+kofRmZm\nPScb/oi4D9jYgb6YWQe18oHf5yQtq94WHFD3Q5IWS+qT1NfCbZlZm400/N8FjgDmAeuBb9b9YEQs\niYj5ETF/hLdlZqNgROGPiIGI2BERO4HvAQva2y0zG20jCr+k6U1nPwSsqPtZM+tN2XX7Jd0EnAxM\nAQaAS6vz84AA1gCfjoj12Rvr4rr9kydPTtZnzJiRrM+ZM2fEbXPjtkcddVSy/sYbbyTrqbUKcvPS\nc/vMr1u3LlnPrX+fGu/O7WG/bdu2ZH3s2LHJ+tKlS2tr48ePT7bNHXuRm8+fm5OfetwGBgaSbefO\nnZusD3fd/uxBPhFx4RAXXzucKzez3uXDe80K5fCbFcrhNyuUw29WKIffrFA9tUX3cccdl2z/1a9+\ntbZ20EEHJdtOmjQpWU9NPYX09NKXX3452TY33Tg3ZJUb8kotO55benvlypXJ+sKFC5P1vr70Udup\nbbgPOKD2qHAAZs+enaznrF69uraW2x5806ZNyXpuym9uCDU11Pj2t7892Tb39+Itus0syeE3K5TD\nb1Yoh9+sUA6/WaEcfrNCOfxmher4OH9qvPz+++9Ptp8+fXptLTdOn6u3slRzbonp3Fh7qyZOnFhb\nmzJlSrLtRRddlKyffvrpyfpnPvOZZD01Jfj1119Ptn3qqaeS9dQ4PqSnYbc6nTg3lTl3HEGqfW66\n8KGHHpqse5zfzJIcfrNCOfxmhXL4zQrl8JsVyuE3K5TDb1aojo7zT5kyJc4+++za+hVXXJFs/+ST\nT9bWcksx5+q57Z5TcmO+qXF4gGeffTZZzy2fnVrLILWsN8C0adOS9XPPPTdZT22DDek5+bnfyXve\n856W6qn7nhvHzz1uuS24c1JrMOT+nlLrXjz33HNs27bN4/xmVs/hNyuUw29WKIffrFAOv1mhHH6z\nQjn8ZoXK7tIraRbwfWAasBNYEhHfkTQZ+C9gNo1tuhdGxEup69q+fTsbNmyorefGu1NzpHPbWOeu\nOzfmnBrXza2zvnHjxmT96aefTtZzfUutF5CbM5/bU+DWW29N1pcvX56sp8b5c9um58bic/slpLYn\nz93v3Jz63Fh8rn1qnD93DEFqS/fcY9JsOM/824EvRMRc4Djgs5LeBVwC3BsRc4B7q/NmtofIhj8i\n1kfEo9XpTcBKYCZwDnBD9WM3AOlDwcysp+zWe35Js4FjgAeBgyNiPTT+QQBT2905Mxs9ww6/pPHA\nj4HPR8Sru9FusaQ+SX2593Bm1jnDCr+kvWkE/wcRcUt18YCk6VV9OjDkJ3kRsSQi5kfE/FYnQ5hZ\n+2TDr8bHktcCKyPiW02l24BF1elFwE/a3z0zGy3ZoT7geOBjwHJJj1WXfRm4ArhZ0ieBZ4ALcle0\nbds21q5dW1vPTS/u7++vrY0bNy7ZNreEdW6I5IUXXqitPf/888m2e+2Vfphz04lzw0qpabW5JaRz\nU1dT9xtg7ty5yfqWLVtqa7nh15deSo4cZx+3VN9Tw4CQHwrMtc9t0Z2aSv3KK68k286bN6+2tmLF\nimTbZtnwR8QvgbpByVOHfUtm1lN8hJ9ZoRx+s0I5/GaFcvjNCuXwmxXK4Tcr1HDG+dtm69atPPbY\nY7X1W265pbYG8IlPfKK2llveOredc27qa2pabW4cPjfmmzvyMbcFeGo6c25r8tyxFbmty9evXz/i\n68/1LXd8RCu/s1anC7cynRjSxxEcdthhybYDAwMjvt1mfuY3K5TDb1Yoh9+sUA6/WaEcfrNCOfxm\nhXL4zQrV0S26JbV0Y2eeeWZt7Ytf/GKy7dSp6SUGc/PWU+O6ufHq3Dh9bpw/N96duv7UEtGQH+fP\nHcOQq6fuW65tru85qfapsfLhyP3Ockt3p+bzL1u2LNl24cKFyXpEeItuM6vn8JsVyuE3K5TDb1Yo\nh9+sUA6/WaEcfrNCdXycP7VOfG5stBWnnHJKsn755Zcn66njBCZOnJhsm1sbP3ccQG6cP3ecQUpq\ny3TIHweQ2ocB0r/TzZs3J9vmHpecVN9z895z6xjkfqf33HNPsr5y5cra2tKlS5NtczzOb2ZJDr9Z\noRx+s0I5/GaFcvjNCuXwmxXK4TcrVHacX9Is4PvANGAnsCQiviPpMuBTwK7N6b8cEXdkrqtzBxV0\n0Dvf+c5kfcqUKcl6bg34Qw45JFlfs2ZNbS03nv3kk08m67bnGe44/3A27dgOfCEiHpU0AXhE0q4j\nGL4dEd8YaSfNrHuy4Y+I9cD66vQmSSuBmaPdMTMbXbv1nl/SbOAY4MHqos9JWibpOkkH1LRZLKlP\nUl9LPTWzthp2+CWNB34MfD4iXgW+CxwBzKPxyuCbQ7WLiCURMT8i5rehv2bWJsMKv6S9aQT/BxFx\nC0BEDETEjojYCXwPWDB63TSzdsuGX40lUK8FVkbEt5oun970Yx8CVrS/e2Y2WoYz1HcC8AtgOY2h\nPoAvAxfSeMkfwBrg09WHg6nreksO9Zn1kuEO9e1R6/abWZ7n85tZksNvViiH36xQDr9ZoRx+s0I5\n/GaFcvjNCuXwmxXK4TcrlMNvViiH36xQDr9ZoRx+s0I5/GaFGs7qve30AvB00/kp1WW9qFf71qv9\nAvdtpNrZt0OH+4Mdnc//Rzcu9fXq2n692rde7Re4byPVrb75Zb9ZoRx+s0J1O/xLunz7Kb3at17t\nF7hvI9WVvnX1Pb+ZdU+3n/nNrEscfrNCdSX8ks6Q9GtJqyRd0o0+1JG0RtJySY91e3/Bag/EDZJW\nNF02WdI9kn5bfR9yj8Qu9e0ySWurx+4xSWd1qW+zJP1c0kpJv5L0t9XlXX3sEv3qyuPW8ff8ksYA\nvwFOA/qBh4ELI+LxjnakhqQ1wPyI6PoBIZJOAjYD34+IP6suuxLYGBFXVP84D4iIL/VI3y4DNnd7\n2/ZqN6npzdvKA+cCF9HFxy7Rr4V04XHrxjP/AmBVRKyOiG3Aj4BzutCPnhcR9wEbB118DnBDdfoG\nGn88HVfTt54QEesj4tHq9CZg17byXX3sEv3qim6EfybwbNP5frr4AAwhgJ9JekTS4m53ZggH79oW\nrfo+tcv9GSy7bXsnDdpWvmceu5Fsd99u3Qj/UFsJ9dJ44/ER8RfAmcBnq5e3NjzD2ra9U4bYVr4n\njHS7+3brRvj7gVlN5w8B1nWhH0OKiHXV9w3ArfTe1uMDu3ZIrr5v6HJ/fqeXtm0falt5euCx66Xt\n7rsR/oeBOZIOk7QP8FHgti70449IGld9EIOkccDp9N7W47cBi6rTi4CfdLEvf6BXtm2v21aeLj92\nvbbdfVeO8KuGMq4CxgDXRcTXOt6JIUg6nMazPTSmO/+wm32TdBNwMo0pnwPApcB/AzcD7wCeAS6I\niI5/8FbTt5PZzW3bR6lvddvKP0gXH7t2bnfflv748F6zMvkIP7NCOfxmhXL4zQrl8JsVyuE3K5TD\nb1Yoh9+sUP8PWAxetwduyp0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2367fa21f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0].reshape(28, 28), cmap = 'gray')\n",
    "plt.title(label_set.get(np.argmax(y_train[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define FashionCNN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropout, batch_normalization, he_initialization,....\n",
    "class FashionCNN:\n",
    "    def __init__(self, activation_fn = tf.nn.relu,\n",
    "                 initializer = tf.contrib.layers.variance_scaling_initializer(), l2_scale = 0.01):\n",
    "        \n",
    "        with tf.variable_scope('input_layer'):\n",
    "            self._x = tf.placeholder(dtype = tf.float32, shape = [None,28,28,1])\n",
    "            self._y = tf.placeholder(dtype = tf.float32, shape = [None, 10])\n",
    "            self._training = tf.placeholder(dtype = tf.bool) # batch normalization \n",
    "            self._keep_prob = tf.placeholder(dtype = tf.float32) # dropout의 keep_prob\n",
    "            \n",
    "        with tf.variable_scope('conv_layer1'):\n",
    "            _conv_pre= tf.layers.conv2d(inputs = self._x, filters = 64, kernel_size = [3,3],\n",
    "                                        padding = 'same', kernel_initializer = initializer,\n",
    "                                        kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale))\n",
    "            _conv_bn = tf.layers.batch_normalization(inputs = _conv_pre, momentum = .9, training = self._training)\n",
    "            _conv_ac = activation_fn(_conv_bn)\n",
    "            \n",
    "        with tf.variable_scope('conv_layer2'):\n",
    "            _conv_pre= tf.layers.conv2d(inputs = _conv_ac, filters = 64, kernel_size = [3,3],\n",
    "                                        padding = 'same', kernel_initializer = initializer,\n",
    "                                        kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale))\n",
    "            _conv_bn = tf.layers.batch_normalization(inputs = _conv_pre, momentum = .9, training = self._training)\n",
    "            _conv_ac = activation_fn(_conv_bn)\n",
    "            \n",
    "        with tf.variable_scope('max_pool1'):\n",
    "            _pooled = tf.layers.max_pooling2d(inputs = _conv_ac, pool_size = [2,2], strides = 2)            \n",
    "\n",
    "        with tf.variable_scope('conv_layer3'):\n",
    "            _conv_pre= tf.layers.conv2d(inputs = _pooled, filters = 128, kernel_size = [3,3],\n",
    "                                        padding = 'same', kernel_initializer = initializer,\n",
    "                                        kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale))\n",
    "            _conv_bn = tf.layers.batch_normalization(inputs = _conv_pre, momentum = .9, training = self._training)\n",
    "            _conv_ac = activation_fn(_conv_bn)\n",
    "            \n",
    "        with tf.variable_scope('conv_layer4'):\n",
    "            _conv_pre= tf.layers.conv2d(inputs = _conv_ac, filters = 128, kernel_size = [3,3],\n",
    "                                        padding = 'same', kernel_initializer = initializer,\n",
    "                                        kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale))\n",
    "            _conv_bn = tf.layers.batch_normalization(inputs = _conv_pre, momentum = .9, training = self._training)\n",
    "            _conv_ac = activation_fn(_conv_bn)\n",
    "\n",
    "        with tf.variable_scope('max_pool2'):\n",
    "            _pooled = tf.layers.max_pooling2d(inputs = _conv_ac, pool_size = [2,2], strides = 2)\n",
    " \n",
    "            \n",
    "        with tf.variable_scope('conv_layer5'):\n",
    "            _conv_pre= tf.layers.conv2d(inputs = _pooled, filters = 256, kernel_size = [3,3],\n",
    "                                        padding = 'same', kernel_initializer = initializer,\n",
    "                                        kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale))\n",
    "            _conv_bn = tf.layers.batch_normalization(inputs = _conv_pre, momentum = .9, training = self._training)\n",
    "            _conv_ac = activation_fn(_conv_bn)\n",
    "\n",
    "        with tf.variable_scope('conv_layer6'):\n",
    "            _conv_pre= tf.layers.conv2d(inputs = _conv_ac, filters = 256, kernel_size = [3,3],\n",
    "                                        padding = 'same', kernel_initializer = initializer,\n",
    "                                        kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale))\n",
    "            _conv_bn = tf.layers.batch_normalization(inputs = _conv_pre, momentum = .9, training = self._training)\n",
    "            _conv_ac = activation_fn(_conv_bn)\n",
    "\n",
    "            \n",
    "        with tf.variable_scope('max_pool3'):\n",
    "            _pooled = tf.layers.max_pooling2d(inputs = _conv_ac, pool_size = [2,2], strides = 2)\n",
    "\n",
    "        with tf.variable_scope('dense_layer1'):\n",
    "            _pooled_vector = tf.reshape(tensor = _pooled, shape = [-1,np.cumprod(_pooled.get_shape().as_list()[-3:])[-1]])\n",
    "            _fc_pre = tf.layers.dense(inputs = _pooled_vector, units = 100, kernel_initializer = initializer,\n",
    "                                      kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale))\n",
    "            _fc_bn = tf.layers.batch_normalization(inputs = _fc_pre, momentum = .9, training = self._training)\n",
    "            _fc_ac = activation_fn(_fc_bn)\n",
    "            \n",
    "        with tf.variable_scope('dense_layer2'):\n",
    "            _fc_pre = tf.layers.dense(inputs = _fc_ac, units = 100, kernel_initializer = initializer,\n",
    "                                      kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale))\n",
    "            _fc_bn = tf.layers.batch_normalization(inputs = _fc_pre, momentum = .9, training = self._training)\n",
    "            _fc_ac = activation_fn(_fc_bn)\n",
    "            _fc_ac = tf.nn.dropout(x = _fc_ac, keep_prob = self._keep_prob)\n",
    "\n",
    "        with tf.variable_scope('output_layer'):\n",
    "            self._score = tf.layers.dense(inputs = _fc_ac, units = 10, kernel_initializer = initializer,\n",
    "                                      kernel_regularizer = tf.contrib.layers.l2_regularizer(scale = l2_scale))\n",
    "        \n",
    "        with tf.variable_scope('loss'):\n",
    "            _ce_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = self._y, logits = self._score))\n",
    "            _reg_term = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "            self._total_loss = _ce_loss +  _reg_term\n",
    "        # 객체변수에 model class 코드로 생성되는 graph의 UPDATE_OPS를 저장\n",
    "        self._update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) \n",
    "        \n",
    "        with tf.variable_scope('predict'):\n",
    "            self._prediction = tf.argmax(input = self._score, axis = 1)\n",
    "    \n",
    "    def predict(self, sess, x_data, training = False, keep_prob = 1.):\n",
    "        feed_predict = {self._x : x_data, self._training : training, self._keep_prob : keep_prob}\n",
    "        return sess.run(fetches = self._prediction, feed_dict = feed_predict)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Solver class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver:\n",
    "    def __init__(self, model, optimizer = tf.train.AdamOptimizer, var_list = None):\n",
    "        self._model = model\n",
    "        self._lr = tf.placeholder(dtype = tf.float32)\n",
    "        self._optimizer = optimizer(learning_rate = self._lr)\n",
    "        \n",
    "        # Solver class는 model class로부터 생성된 instance를 input으로 받음. model class에서 저장한 객체변수를 아래와 같이 활용\n",
    "        with tf.control_dependencies(self._model._update_ops):\n",
    "            self._training_op = self._optimizer.minimize(loss = self._model._total_loss, var_list = var_list)\n",
    "    \n",
    "    def train(self, sess, x_data, y_data, lr, training = True, keep_prob = .5):\n",
    "        feed_train = {self._model._x : x_data, self._model._y : y_data, self._lr : lr,\n",
    "                      self._model._training : training, self._model._keep_prob : keep_prob}\n",
    "        return sess.run(fetches = [self._training_op, self._model._total_loss], feed_dict = feed_train)\n",
    "            \n",
    "    def evaluate(self, sess, x_data, y_data, training = False, keep_prob = 1.):\n",
    "        feed_loss = {self._model._x : x_data, self._model._y : y_data, self._model._training : training,\n",
    "                     self._model._keep_prob : keep_prob}\n",
    "        return sess.run(fetches = self._model._total_loss, feed_dict = feed_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate CNN model and Solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "fashion_classifier = FashionCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_solver = Solver(model = fashion_classifier)\n",
    "sgd_solver = Solver(model = fashion_classifier, optimizer = tf.train.GradientDescentOptimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "batch_size = 100\n",
    "n_epochs = 10\n",
    "tr_loss_history = []\n",
    "val_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :   0, tr_loss : 14.564, val_loss : 25.993\n",
      "step : 100, tr_loss : 7.631, val_loss : 7.673\n",
      "step : 200, tr_loss : 4.336, val_loss : 4.407\n",
      "step : 300, tr_loss : 2.605, val_loss : 2.760\n",
      "step : 400, tr_loss : 1.701, val_loss : 1.746\n",
      "step : 500, tr_loss : 1.328, val_loss : 1.836\n",
      "epoch :   0, tr_loss : 4.327, val_loss : 4.411\n",
      "step :   0, tr_loss : 1.149, val_loss : 1.328\n",
      "step : 100, tr_loss : 1.013, val_loss : 0.995\n",
      "step : 200, tr_loss : 1.025, val_loss : 1.058\n",
      "step : 300, tr_loss : 0.771, val_loss : 0.871\n",
      "step : 400, tr_loss : 0.857, val_loss : 0.885\n",
      "step : 500, tr_loss : 0.841, val_loss : 0.906\n",
      "epoch :   1, tr_loss : 0.917, val_loss : 0.945\n",
      "step :   0, tr_loss : 0.695, val_loss : 0.813\n",
      "step : 100, tr_loss : 0.837, val_loss : 0.684\n",
      "step : 200, tr_loss : 0.664, val_loss : 0.900\n",
      "step : 300, tr_loss : 0.562, val_loss : 0.809\n",
      "step : 400, tr_loss : 0.663, val_loss : 0.817\n",
      "step : 500, tr_loss : 0.832, val_loss : 0.824\n",
      "epoch :   2, tr_loss : 0.738, val_loss : 0.783\n",
      "step :   0, tr_loss : 0.688, val_loss : 0.748\n",
      "step : 100, tr_loss : 0.716, val_loss : 0.743\n",
      "step : 200, tr_loss : 0.720, val_loss : 0.663\n",
      "step : 300, tr_loss : 0.648, val_loss : 0.547\n",
      "step : 400, tr_loss : 0.739, val_loss : 0.924\n",
      "step : 500, tr_loss : 0.678, val_loss : 0.792\n",
      "epoch :   3, tr_loss : 0.697, val_loss : 0.731\n",
      "step :   0, tr_loss : 0.775, val_loss : 0.668\n",
      "step : 100, tr_loss : 0.664, val_loss : 0.901\n",
      "step : 200, tr_loss : 0.734, val_loss : 0.666\n",
      "step : 300, tr_loss : 0.659, val_loss : 0.599\n",
      "step : 400, tr_loss : 0.829, val_loss : 0.627\n",
      "step : 500, tr_loss : 0.629, val_loss : 0.845\n",
      "epoch :   4, tr_loss : 0.672, val_loss : 0.707\n",
      "step :   0, tr_loss : 0.537, val_loss : 0.643\n",
      "step : 100, tr_loss : 0.611, val_loss : 0.682\n",
      "step : 200, tr_loss : 0.597, val_loss : 0.834\n",
      "step : 300, tr_loss : 0.752, val_loss : 0.646\n",
      "step : 400, tr_loss : 0.606, val_loss : 0.652\n",
      "step : 500, tr_loss : 0.612, val_loss : 0.724\n",
      "epoch :   5, tr_loss : 0.644, val_loss : 0.682\n",
      "step :   0, tr_loss : 0.600, val_loss : 0.590\n",
      "step : 100, tr_loss : 0.564, val_loss : 0.605\n",
      "step : 200, tr_loss : 0.679, val_loss : 0.591\n",
      "step : 300, tr_loss : 0.657, val_loss : 0.540\n",
      "step : 400, tr_loss : 0.684, val_loss : 0.598\n",
      "step : 500, tr_loss : 0.517, val_loss : 0.633\n",
      "epoch :   6, tr_loss : 0.621, val_loss : 0.652\n",
      "step :   0, tr_loss : 0.677, val_loss : 0.595\n",
      "step : 100, tr_loss : 0.451, val_loss : 0.794\n",
      "step : 200, tr_loss : 0.667, val_loss : 0.554\n",
      "step : 300, tr_loss : 0.558, val_loss : 0.523\n",
      "step : 400, tr_loss : 0.572, val_loss : 0.615\n",
      "step : 500, tr_loss : 0.681, val_loss : 0.674\n",
      "epoch :   7, tr_loss : 0.581, val_loss : 0.624\n",
      "step :   0, tr_loss : 0.585, val_loss : 0.719\n",
      "step : 100, tr_loss : 0.524, val_loss : 0.607\n",
      "step : 200, tr_loss : 0.528, val_loss : 0.534\n",
      "step : 300, tr_loss : 0.445, val_loss : 0.665\n",
      "step : 400, tr_loss : 0.585, val_loss : 0.547\n",
      "step : 500, tr_loss : 0.758, val_loss : 0.554\n",
      "epoch :   8, tr_loss : 0.555, val_loss : 0.577\n",
      "step :   0, tr_loss : 0.734, val_loss : 0.542\n",
      "step : 100, tr_loss : 0.400, val_loss : 0.469\n",
      "step : 200, tr_loss : 0.587, val_loss : 0.556\n",
      "step : 300, tr_loss : 0.497, val_loss : 0.424\n",
      "step : 400, tr_loss : 0.526, val_loss : 0.520\n",
      "step : 500, tr_loss : 0.568, val_loss : 0.410\n",
      "epoch :   9, tr_loss : 0.513, val_loss : 0.495\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    avg_tr_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    total_batch = int(x_train.shape[0] / batch_size)\n",
    "    \n",
    "    if epoch  <= 8:\n",
    "        \n",
    "        for step in range(total_batch):\n",
    "            tr_indices = np.random.choice(np.arange(x_train.shape[0]), size = batch_size, replace=False)\n",
    "            val_indices = np.random.choice(np.arange(x_val.shape[0]), size = batch_size, replace=False)\n",
    "            batch_xs = x_train[tr_indices]\n",
    "            batch_ys = y_train[tr_indices]\n",
    "            val_xs = x_val[val_indices]\n",
    "            val_ys = y_val[val_indices]\n",
    "            _, tr_loss = adam_solver.train(sess = sess, x_data = batch_xs, y_data = batch_ys, lr = 1e-3)\n",
    "            val_loss = adam_solver.evaluate(sess = sess, x_data = val_xs, y_data = val_ys)\n",
    "\n",
    "            avg_tr_loss += tr_loss / total_batch\n",
    "            avg_val_loss += val_loss / total_batch\n",
    "            if step % 100 == 0:\n",
    "                print('step : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(step, tr_loss, val_loss))\n",
    "\n",
    "        print('epoch : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(epoch, avg_tr_loss, avg_val_loss))\n",
    "        tr_loss_history.append(avg_tr_loss)\n",
    "        val_loss_history.append(avg_val_loss)\n",
    "        \n",
    "    else :\n",
    "\n",
    "        for step in range(total_batch):\n",
    "            tr_indices = np.random.choice(np.arange(x_train.shape[0]), size = batch_size, replace=False)\n",
    "            val_indices = np.random.choice(np.arange(x_val.shape[0]), size = batch_size, replace=False)\n",
    "            batch_xs = x_train[tr_indices]\n",
    "            batch_ys = y_train[tr_indices]\n",
    "            val_xs = x_val[val_indices]\n",
    "            val_ys = y_val[val_indices]\n",
    "            _, tr_loss = sgd_solver.train(sess = sess, x_data = batch_xs, y_data = batch_ys, lr = 1e-3)\n",
    "            val_loss = sgd_solver.evaluate(sess = sess, x_data = val_xs, y_data = val_ys)\n",
    "\n",
    "            avg_tr_loss += tr_loss / total_batch\n",
    "            avg_val_loss += val_loss / total_batch\n",
    "            if step % 100 == 0:\n",
    "                print('step : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(step, tr_loss, val_loss))\n",
    "\n",
    "        print('epoch : {:3}, tr_loss : {:.3f}, val_loss : {:.3f}'.format(epoch, avg_tr_loss, avg_val_loss))\n",
    "        tr_loss_history.append(avg_tr_loss)\n",
    "        val_loss_history.append(avg_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x236840a6978>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x236833317f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_history, label = 'train')\n",
    "plt.plot(val_loss_history, label = 'validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat = fashion_classifier.predict(sess=sess, x_data = x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 91.16%\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : {:.2%}'.format(np.mean(np.argmax(y_test, axis = 1) == hat)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
